{"cells":[{"cell_type":"markdown","id":"4a7c8010","metadata":{"id":"4a7c8010"},"source":["# Importing all libraries"]},{"cell_type":"code","execution_count":null,"id":"c10f5459","metadata":{},"outputs":[],"source":["import io, os, re\n","#os.environ['GOOGLE_APPLICATION_CREDENTIALS']= '/Users/dhirajhasija/opt/anaconda3/vision.json'\n","#from Levenshtein import distance as lev\n","#from google.cloud import vision\n","#from google.cloud.vision_v1 import types\n","#from google.cloud.vision_v1 import AnnotateImageResponse\n","import json\n","import numpy as np\n","import pandas as pd\n","import argparse\n","from enum import Enum\n","import cv2\n","\n","#from google.cloud import vision\n","from PIL import Image, ImageDraw, ImageOps\n","#client = vision.ImageAnnotatorClient()\n","pd.set_option('display.max_rows', None)\n","import fastwer\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.metrics.pairwise import euclidean_distances"]},{"cell_type":"code","execution_count":null,"id":"9719660e","metadata":{"id":"9719660e"},"outputs":[],"source":["client = vision.ImageAnnotatorClient()"]},{"cell_type":"code","execution_count":15,"id":"KXzmSwHmYgY8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4773,"status":"ok","timestamp":1656088166515,"user":{"displayName":"Dhiraj Hasija","userId":"16227978329846526818"},"user_tz":-330},"id":"KXzmSwHmYgY8","outputId":"cab89b8f-75c5-4f28-d894-dd7c13dd9924"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastwer\n","  Using cached fastwer-0.1.3.tar.gz (4.6 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/cb/4d/a497cf1554862372a25576ac38c60e4ae4494cd6795aa52a21eab041cfd2/fastwer-0.1.3.tar.gz#sha256=2681072b2b35e6a2308d2ff269e582813b96aef855782adc86fc348778c024a1 (from https://pypi.org/simple/fastwer/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Using cached fastwer-0.1.tar.gz (3.6 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/87/21/6b852ad491a4016d47b46b441475836a47ceebfaebb6bbc81505005419ea/fastwer-0.1.tar.gz#sha256=fe3feac6c3440d738724af756edb488d40221dcbcaa41cefa7aad05e72e618dd (from https://pypi.org/simple/fastwer/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","\u001b[31mERROR: Could not find a version that satisfies the requirement fastwer (from versions: 0.1, 0.1.3)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for fastwer\u001b[0m\n"]}],"source":["!pip install fastwer"]},{"cell_type":"code","execution_count":null,"id":"a9acefb3","metadata":{"id":"a9acefb3"},"outputs":[],"source":["client = vision.ImageAnnotatorClient()\n","    # [END vision_python_migration_client]\n","\n","    # The name of the image file to annotate\n","file_name = os.path.abspath('Fontfre_Clean_TE.png')\n","\n","    # Loads the image into memory\n","with io.open(file_name, 'rb') as image_file:\n","    content = image_file.read()\n","\n","image = vision.Image(content=content)\n","    \n","#response = client.document_text_detection(image=image)\n","#texts = response.full_text_annotation\n","\n"]},{"cell_type":"code","execution_count":null,"id":"47ed2a2f","metadata":{},"outputs":[],"source":["response = client.document_text_detection(image=image)"]},{"cell_type":"markdown","id":"1338c529","metadata":{"id":"1338c529"},"source":["# Writing detected words adjacent to image"]},{"cell_type":"code","execution_count":null,"id":"4cc2bf38","metadata":{"id":"4cc2bf38"},"outputs":[],"source":["#Writing words adjacent to image \n","\n","\n","from PIL import ImageFont\n","\n","def draw_boxes(image, bounds, color, words):\n","    draw = ImageDraw.Draw(image)\n","    \n","    for i in range(0,len(words)):\n","            draw.text((bounds[i].vertices[0].x-1000,bounds[i].vertices[0].y), words[i],font=ImageFont.truetype('/Library/Fonts/Arial.ttf', 15), align =\"centre\", strokewidth = 2, fill =\"white\") \n","\n","    for bound in bounds:\n","        draw.polygon(\n","            [\n","                bound.vertices[0].x-1000,\n","                bound.vertices[0].y,\n","                bound.vertices[1].x-1000,\n","                bound.vertices[1].y,\n","                bound.vertices[2].x-1000,\n","                bound.vertices[2].y,\n","                bound.vertices[3].x-1000,\n","                bound.vertices[3].y,\n","            ], None, color,\n","        )\n","            \n","    return image\n","\n","def get_document_bounds(document):\n","    bounds = []\n","    words = []\n","    for page in document.pages:\n","        for block in page.blocks:\n","            for paragraph in block.paragraphs:\n","                for word in paragraph.words:\n","                    bounds.append(word.bounding_box)\n","                    word_text = ''.join([symbol.text for symbol in word.symbols])\n","                    words.append(word_text)\n","\n","    return bounds, words\n","\n","def render_doc_text(filein, fileout, document):\n","    image = Image.open(filein)\n","    image = image.rotate(270)\n","    bounds, words = get_document_bounds(document)\n","    draw_boxes(image, bounds, \"yellow\", words)\n","\n","    if fileout != 0:\n","        image.save(fileout)\n","        \n","        \n","        \n","def image_to_byte_array(image:Image):\n","    imgByteArr = io.BytesIO()\n","    image.save(imgByteArr, format='JPEG')\n","    imgByteArr = imgByteArr.getvalue()\n","    return imgByteArr\n","\n","\n","directory = 'Improvement tests'\n","\n","for folder in os.listdir(directory):\n","    if folder in ['Bounded + text']:\n","        folderpath = os.path.join(directory, folder)\n","        for folder1 in os.listdir(folderpath):\n","            if folder1 in ['Restoration']:\n","                folderpath1 = os.path.join(folderpath, folder1)\n","                if os.path.isdir(folderpath1) == True:\n","                    for imagename in os.listdir(folderpath1):\n","                        if imagename != '.DS_Store':   \n","                            imagepath = os.path.join(folderpath1, imagename)\n","                            imagepath = os.path.abspath(imagepath)\n","                            image = ImageOps.exif_transpose(Image.open(imagepath))\n","                            image = image.rotate(270)\n","                            content = image_to_byte_array(image)\n","                            image = vision.Image(content=content)\n","                            response = client.document_text_detection(image=image)  \n","                            document = response.full_text_annotation\n","                            render_doc_text(imagepath,imagepath.split('.')[0] + '-words.jpg', document)"]},{"cell_type":"markdown","id":"f94b7b10","metadata":{"id":"f94b7b10"},"source":["# Drawing bounding boxes and creating output dataframe"]},{"cell_type":"code","execution_count":null,"id":"5199d12e","metadata":{"id":"5199d12e"},"outputs":[],"source":["Distortion_map = {\n","    'S':'Single',\n","    'M':'Multiple'\n","}\n","\n","Light_condition_map = {'1':'Day','2':'Day + Cieling','3':'Night + Table', '4' : 'Table + Shadow', '5': 'Table + Grid Shadow'}\n","\n","\n","Blur_map = {'SMb1' : 'Horizontal', 'SMb2':'2D', 'MMb1' : 'Horizontal', 'MMb2':'2D','SOb1': 'f_22.5', 'SOb2' : 'f_21.5', 'SOb3': 'f_20.5', 'SOb4':'f_19.5', 'MOb1': 'f_21.66', 'MOb2':'f_19.66'}\n","\n","def draw_boxes(image, bounds, color):\n","    draw = ImageDraw.Draw(image)\n","\n","    for bound in bounds:\n","        draw.polygon(\n","            [\n","                bound.vertices[0].x,\n","                bound.vertices[0].y,\n","                bound.vertices[1].x,\n","                bound.vertices[1].y,\n","                bound.vertices[2].x,\n","                bound.vertices[2].y,\n","                bound.vertices[3].x,\n","                bound.vertices[3].y,\n","            ],\n","            None,\n","            color,\n","        )\n","        \n","        \n","    return image\n","\n","def get_document_bounds(document, feature):\n","    bounds = []\n","    for page in document.pages:\n","        for block in page.blocks:\n","            for paragraph in block.paragraphs:\n","                for word in paragraph.words:\n","                    for symbol in word.symbols:\n","                        if feature == FeatureType.SYMBOL:\n","                        \n","                            bounds.append(symbol.bounding_box)\n","\n","                    if feature == FeatureType.WORD:\n","                        bounds.append(word.bounding_box)\n","\n","                if feature == FeatureType.PARA:\n","                    bounds.append(paragraph.bounding_box)\n","\n","            if feature == FeatureType.BLOCK:\n","                bounds.append(block.bounding_box)\n","\n","    return bounds\n","\n","def render_doc_text(filein, fileout, document):\n","    image = Image.open(filein)\n","    bounds = get_document_bounds(document, FeatureType.BLOCK)\n","    draw_boxes(image, bounds, \"blue\")\n","    bounds = get_document_bounds(document, FeatureType.PARA)\n","    draw_boxes(image, bounds, \"red\")\n","    bounds = get_document_bounds(document, FeatureType.WORD)\n","    draw_boxes(image, bounds, \"yellow\")\n","\n","    if fileout != 0:\n","        image.save(fileout)\n","        \n","class FeatureType(Enum):\n","    PAGE = 1\n","    BLOCK = 2\n","    PARA = 3\n","    WORD = 4\n","    SYMBOL = 5"]},{"cell_type":"code","execution_count":null,"id":"13e1ce51","metadata":{},"outputs":[],"source":["#For smart Doc improved images\n","try:\n","    del df_comparison\n","except:\n","    print('df_comparison does not exist')\n","    \n","df_comparison = pd.DataFrame(columns= ['Imagename','Distortion', 'Doc_no', 'Light_condition', 'Long_angle','Lateral_angle','Type_of_blur','Type_of_sharpening','no_of_bounding_boxes', 'words','confidence'])\n","\n","def image_to_byte_array(image:Image):\n","    imgByteArr = io.BytesIO()\n","    image.save(imgByteArr, format='JPEG')\n","    imgByteArr = imgByteArr.getvalue()\n","    return imgByteArr\n","\n","# Name the directory containing image folders\n","directory = 'Improvement tests'\n","\n","for folder in os.listdir(directory):\n","#Enter name of folders to compare; filename is folder name\n","    if folder in ['Sample']:\n","        folderpath = os.path.join(directory, folder)\n","        #for folder1 in os.listdir(folderpath):\n","        #    if folder1 not in ['.Ds_Store']:\n","        #        folderpath1 = os.path.join(folderpath, folder1)\n","        #        if os.path.isdir(folderpath1) == True:\n","        for imagename in os.listdir(folderpath):\n","            if imagename != '.DS_Store':   \n","                imagepath = os.path.join(folderpath, imagename)\n","                imagepath = os.path.abspath(imagepath)\n","                image = ImageOps.exif_transpose(Image.open(imagepath))\n","                \n","                content = image_to_byte_array(image)\n","                image = vision.Image(content=content)\n","                response = client.document_text_detection(image=image)\n","                \n","                document = response.full_text_annotation\n","                \n","                render_doc_text(imagepath,imagepath.split('.')[0] + 'bounded.jpg', document)\n","\n","                for page in document.pages:\n","                    df_sect = pd.DataFrame(columns=['word','confidence'])\n","                    for block in page.blocks:\n","                        for paragraph in block.paragraphs:\n","                            for word in paragraph.words:\n","\n","                                word_text = ''.join([\n","                                        symbol.text for symbol in word.symbols\n","                                    ])\n","\n","\n","                                df_sect =df_sect.append(\n","                                dict(\n","                                    word = word_text,\n","                                    confidence = word.confidence\n","                                ), ignore_index = True\n","                                )\n","\n","                    print(imagename)\n","\n","                    if len(imagename.split('_')) == 9:\n","                        df_comparison = df_comparison.append(\n","                            dict( \n","                                Imagename = imagename.split('.')[0],\n","                                Distortion = Distortion_map[imagename.split('_')[0]],\n","                                Doc_no = imagename.split('_')[3][1:],\n","                                Light_condition = Light_condition_map[imagename.split('_')[4][1:]],\n","                                Long_angle = imagename.split('_')[7][1:-4],\n","                                Lateral_angle = imagename.split('_')[6][1:],\n","                                Type_of_blur = Blur_map[(imagename.split('_')[0] +imagename.split('_')[8][:-4])],\n","                                Type_of_sharpening = 'NA',\n","                                no_of_bounding_boxes = len(df_sect),\n","                                words = df_sect['word'].tolist() ,\n","                                confidence = df_sect['confidence'].mean(),\n","                                confidence_med = df_sect['confidence'].median()\n","                            ), ignore_index= True\n","                        )\n","\n","                    if len(imagename.split('_')) == 2:\n","                        df_comparison = df_comparison.append(\n","                            dict( \n","                                Imagename = imagename.split('.')[0],\n","                                Distortion = 'NA',\n","                                Doc_no = imagename.split('_')[1][:-4],\n","                                Light_condition = 'NA',\n","                                Long_angle = 'NA',\n","                                Lateral_angle = 'NA',\n","                                Type_of_blur = 'NA',\n","                                Type_of_sharpening = 'NA',\n","                                no_of_bounding_boxes = len(df_sect),\n","                                words = df_sect['word'].tolist() ,\n","                                confidence = df_sect['confidence'].mean(),\n","                                confidence_med = df_sect['confidence'].median()\n","                            ), ignore_index= True\n","                        )\n","\n","                    if len(imagename.split('_')) == 10:\n","                        df_comparison = df_comparison.append(\n","                            dict( \n","                                Imagename = imagename.split('.')[0],\n","                                Distortion = Distortion_map[imagename.split('_')[0]],\n","                                Doc_no = imagename.split('_')[3][1:],\n","                                Light_condition = Light_condition_map[imagename.split('_')[4][1:]],\n","                                Long_angle = imagename.split('_')[7][1:],\n","                                Lateral_angle = imagename.split('_')[6][1:],\n","                                Type_of_blur = Blur_map[(imagename.split('_')[0] +imagename.split('_')[8])],\n","                                Type_of_sharpening = (imagename.split('_')[9]).split('.')[0],\n","                                no_of_bounding_boxes = len(df_sect),\n","                                words = df_sect['word'].tolist() ,\n","                                confidence = df_sect['confidence'].mean(),\n","                                confidence_med = df_sect['confidence'].median()\n","                            ), ignore_index= True\n","                        )"]},{"cell_type":"code","execution_count":null,"id":"b7cff88a","metadata":{"id":"b7cff88a"},"outputs":[],"source":["#Creating a count_vectorizer method\n","count_vectorizer = CountVectorizer(stop_words='english')\n","count_vectorizer = CountVectorizer()"]},{"cell_type":"code","execution_count":null,"id":"7e6f7096","metadata":{"id":"7e6f7096"},"outputs":[],"source":["a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_30.txt', \"r\")\n","page_30 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_29.txt', \"r\")\n","page_29 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_28.txt', \"r\")\n","page_28 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_27.txt', \"r\")\n","page_27 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_26.txt', \"r\")\n","page_26 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_24.txt', \"r\")\n","page_24 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_25.txt', \"r\")\n","page_25 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_23.txt', \"r\")\n","page_23 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_22.txt', \"r\")\n","page_22 = (a.read())\n","\n","a = open('/Users/dhirajhasija/Downloads/OCR project/Ground Truth/page_21.txt', \"r\")\n","page_21 = (a.read())"]},{"cell_type":"code","execution_count":null,"id":"ce1d31fe","metadata":{"id":"ce1d31fe"},"outputs":[],"source":["paytm = 'Paytm, Payment, Successful, ₹, 3,002, Paid, at, Jassowal, HP, Centre, BHADSON, ROAD, PATIALA, From, QR, 07, Nov, 2021,, 04:43:48, PM, Payment, Details, Txn, ID, 202111071112128001101680, 66761785546, Order, ID, 20211107164346004724, 10387082, Card, No., Transaction, Type, SALE, Serial, No., 1490593894, MID, Jassow20767837367485, TID, 10387082, Customer, Copy, PAYTM, POS, Version, 1.0.0.0'\n","HP = 'G-50, HP, HDFC, BANK, JASSOWAL,, HP, CENTRE, JASSOWAL, BHADSON, ROAD, PATIALA, M:9876317400, A09/2021, ORIGINAL, 07-NOV-2021, 17:07:50, TXN, NO:, 1110708612, INVOICE, NO:, 652744, VEHICLE, NO:, NOT, ENTERED, BANK, PRESET:, NOT, ENTERED, HDFC, NOZZLE, NO, :, 1, PRODUCT:, PETROL, RATE, :, 105.26, INR/Ltr, VOLUMNE:, 28.52, Ltr, AMOUNT:, 3002.01, INR, 5001, Thank, You!, VIS'\n","gvr = 'A110DEE, ESS, ENTERPRICES, PATIALA, IOCL, DEALER, Bill, No:Jan-875537-ORGNL, Trns.ID:0000000300644811, Atnd.ID:, Receipt:Physical, Receipt, Vehi.No:2, Mob.No, :NotEntered, Date, :19/01/2022, Time, :13:48:55, FP., ID, :2, Nozl, No, :, 2, Fuel, :PETROL, Preset, :NON, PRESET, Rate, :Rs.95.41, Sale, :Rs.2898.55, Volume, :30.38L, THANKS, VISIT, AGAIN, GVR'\n","qrcode = 'more, ., Discount, Supermarket, More, Retail, Private, Limited, (, Formerly, Knows, as, More, Retail, Limited, ), CIN, No., :, U65990MH1988PTC048117, Bhadson, Road, ,, Patiala, JP, Propertes, ,, Near, State, Bank, of, Patiala, ,, Punjab, Tel, :, +917717303803, GSTIN, :, 03AAACP2678Q1ZO, FSSAI, License, No, :, 12115681000018, TAX, Invoice, Date, :, 17, /, 11, /, 21, 19, :, 04, :, 47, CM, No, .:, 1806-4143622422, Staff, :, Talib, Trans, :, 621520, Ref, ., No, :, POS, No, :, J4143, Description, HSN, Qty, Unit, Rate, Amount, 1, SGST, @, 2.5, %, CGST, @, 2.5, %, Borges, Extra, Light, Olive, Oil, 2, Ltr, Pet, Bottle, 15099010, 1ea, 1249, 1249, Jivo, Canola, Oil, 1, Ltr, Pet, Bottle, 15141920, 2ea, 255, 510, 2, SGST, @, 6, %, CGST, @, 6, %, Mothers, Recipe, Schezwan, Chutney, 250, gm, Bottle, 21039090, 1ea, 80, 80, 3, SGST, @, 9, %, CGST, @, 9, %, Vega, Paddle, Brush, E11, -, PB, 96032900, 1ea, 269.1, 269.1, Items, :, 4, Qty, :, 5, Amt, :, 2,108.10, Payment, Summary, ICICI, Bank, EDC,2,108.10, Appr, Code, 8520, *, YOUR, CLUBMORE, SAVINGS,*, 1,620.90, CLUBMORE, Membership, No.,:,GST, Reciept, Summary, Sr, Taxable, Amt, ., 1, /, SGST, CGST, CESS, &, Adv, Total, Amt., 1, 1,675.23, 2, 71.43, 3, 228.05, 41.88, 41.88, 0.00, 1,759.00, 4.29, 4.29, 0.00, 80.00, 20.52, 20.52, 0.00, 269.10, T, 1,974.71, 66.69, 66.69, 0.00, 2,108.10'\n","Invoice_4 = 'August, House, Cafe, Adinath, Cafe, LLP, GSTIN, :, 08ABPFA1865M1ZV, Name:, Date:, 22/03/22, Dine, In:, O3, 19:06, Cashier:, biller, Bill, No.:, 1145, Persons:, 1, No.Item, Qty., Price, Amount, 1, Iced, Americano, 1, 150.00, 150.00, Total, Qty:, 1, Sub, Total, 150.00. Service, Charge, 7.50, CGST, 2.5%, 3.75,, SGST, 2.5%, 3.75, Grand, Total, 165.00, FSSAI, Lic, No., 12219026001304, Thanks'\n","Invoice_2 = \"HP,ADHOC,RAM,FILLING,STN,VILL.,RAIMALIPUR.,DIST,.M/GARH.HARYANA.,GST.,06AFQPA2094F1ZL,MOB.,9783960007.,Bill,No:95954-ORGNL,Trns.,ID:,Atnd.,ID:,Receipt:,Physical,Receipt,Vehi.,,No:7169,Mob.,No,:,NotEntered,Date,:, 07/03/2022,Time,:,15:01:12,FP.,ID,:,2,Nozl,No:2,Fuel,:,Density,:,830kg/m3,Preset,:,NON,PRESET,Rate,:,Rs.,87.26,Sale,:,Rs.,5835.07,Volume,:,66.87Lts.\"\n","Invoice_3 = 'Half, Light, Coffee, Roasters, F-58, ,Sunder, Marg, , C, Scheme, Ph., 9928278748, Email:, halflightcoffee@gmail.com, GSTIN:, 08AVWPG4893Q1ZA, Type:, Take, Away, Bill, No., :119919, Delivery, Boy:, Date:2022-03-21, 16:32:20, Kots:122, Item, Qty, Amt, Iced, Americano, 1, 133.33, Total, Qty:, 1, SubTotal, :, 133.33, GST, 6.67, CGST, @2.5, 3.33, SGST, @2.5, 3.33, Round, Off:, 0.00, Total, Invoice, Value, 140, Thank, you, , visit, again!, Powered, by, -, POSIST '"]},{"cell_type":"code","execution_count":null,"id":"151054d2","metadata":{"id":"151054d2"},"outputs":[],"source":["# Calculatring jaccard\n","def jaccard(string, folder):\n","    list1 = string\n","    list2 = ''\n","    if folder == '21':\n","        list2 = page_21\n","    \n","    elif folder == '22':\n","        list2 = page_22\n","        \n","    elif folder == '23':\n","        list2 = page_23\n","    \n","    elif folder == '24':\n","        list2 = page_24\n","        \n","    elif folder == '25':\n","        list2 = page_25\n","        \n","    elif folder == '26':\n","        list2 = page_26\n","        \n","    elif folder == '27':\n","        list2 = page_27\n","        \n","    elif folder == '28':\n","        list2 = page_28\n","        \n","    elif folder == '29':\n","        list2 = page_29\n","        \n","    elif folder == '30':\n","        list2 = page_30\n","\n","    elif folder == 'paytm':\n","        list2 = paytm\n","\n","    elif folder == 'HP':\n","        list2 = HP\n","\n","    elif folder == 'gvr':\n","        list2 = gvr\n","\n","    elif folder == 'Invoice_2':\n","        list2 = Invoice_2\n","\n","    elif folder == 'Invoice_3':\n","        list2 = Invoice_3\n","\n","    elif folder == 'Invoice_4':\n","        list2 = Invoice_4\n","\n","    \n","    list1 = re.split(r'\\s+|[,:/!=\\'€\"_()\\[\\];\\.-]\\s*', list1)\n","    list2 = re.split(r'\\s+|[,:/!=\\'€\"_()\\[\\];\\.-]\\s*', list2)\n","    \n","    list1 = [i for i in list1 if i]\n","    list2 = [i for i in list2 if i]\n","    \n","    intersection = len(list(set(list1).intersection(list2)))\n","    union = (len(list1) + len(list2)) - intersection\n","    return float(intersection) / union"]},{"cell_type":"code","execution_count":null,"id":"e79c3399","metadata":{"id":"e79c3399"},"outputs":[],"source":["#Calculating cosine sim\n","def cos_sim(string, folder):\n","        \n","    cos_simm = np.zeros((2,2))\n","    \n","    if folder == '21':\n","        list2 = page_21\n","    \n","    elif folder == '22':\n","        list2 = page_22\n","        \n","    elif folder == '23':\n","        list2 = page_23\n","    \n","    elif folder == '24':\n","        list2 = page_24\n","        \n","    elif folder == '25':\n","        list2 = page_25\n","        \n","    elif folder == '26':\n","        list2 = page_26\n","        \n","    elif folder == '27':\n","        list2 = page_27\n","        \n","    elif folder == '28':\n","        list2 = page_28\n","        \n","    elif folder == '29':\n","        list2 = page_29\n","        \n","    elif folder == '30':\n","        list2 = page_30\n","        \n","    elif folder == 'paytm':\n","        list2 = paytm\n","    \n","    elif folder == 'HP':\n","        list2 = HP\n","        \n","    elif folder == 'gvr':\n","        list2 = gvr\n","        \n","    elif folder == 'Invoice_2':\n","        list2 = Invoice_2\n","        \n","    elif folder == 'Invoice_3':\n","        list2 = Invoice_3\n","        \n","    elif folder == 'Invoice_4':\n","        list2 = Invoice_4\n","        \n","\n","    document = [list2,string]\n","    document = count_vectorizer.fit_transform(document)\n","    cos_simm = cosine_similarity(document, document)\n","\n","    \n","    return (cos_simm[1][0])"]},{"cell_type":"code","execution_count":null,"id":"60e82540","metadata":{"id":"60e82540"},"outputs":[],"source":["#Calculating cosine sim\n","def euc_dist(string, folder):\n","        \n","    cos_simm = np.zeros((2,2))\n","    \n","    if folder == '21':\n","        list2 = page_21\n","    \n","    elif folder == '22':\n","        list2 = page_22\n","        \n","    elif folder == '23':\n","        list2 = page_23\n","    \n","    elif folder == '24':\n","        list2 = page_24\n","        \n","    elif folder == '25':\n","        list2 = page_25\n","        \n","    elif folder == '26':\n","        list2 = page_26\n","        \n","    elif folder == '27':\n","        list2 = page_27\n","        \n","    elif folder == '28':\n","        list2 = page_28\n","        \n","    elif folder == '29':\n","        list2 = page_29\n","        \n","    elif folder == '30':\n","        list2 = page_30\n","        \n","    elif folder == 'paytm':\n","        list2 = paytm\n","    \n","    elif folder == 'HP':\n","        list2 = HP\n","        \n","    elif folder == 'gvr':\n","        list2 = gvr\n","        \n","    elif folder == 'Invoice_2':\n","        list2 = Invoice_2\n","        \n","    elif folder == 'Invoice_3':\n","        list2 = Invoice_3\n","        \n","    elif folder == 'Invoice_4':\n","        list2 = Invoice_4\n","        \n","\n","    document = [list2,string]\n","    document = count_vectorizer.fit_transform(document)\n","    cos_simm = euclidean_distances(document, document)\n","\n","    \n","    return (cos_simm[1][0])"]},{"cell_type":"code","execution_count":null,"id":"de2d4b53","metadata":{"id":"de2d4b53"},"outputs":[],"source":["def CERT(string, folder):\n","    \n","    st1 = string\n","    st2 = ''\n","    list2 = ''\n","    \n","    if folder == '21':\n","        list2 = page_21\n","    \n","    elif folder == '22':\n","        list2 = page_22\n","        \n","    elif folder == '23':\n","        list2 = page_23\n","    \n","    elif folder == '24':\n","        list2 = page_24\n","        \n","    elif folder == '25':\n","        list2 = page_25\n","        \n","    elif folder == '26':\n","        list2 = page_26\n","        \n","    elif folder == '27':\n","        list2 = page_27\n","        \n","    elif folder == '28':\n","        list2 = page_28\n","        \n","    elif folder == '29':\n","        list2 = page_29\n","        \n","    elif folder == '30':\n","        list2 = page_30\n","\n","    elif folder == 'paytm':\n","        list2 = paytm\n","    \n","    elif folder == 'HP':\n","        list2 = HP\n","        \n","    elif folder == 'gvr':\n","        list2 = gvr\n","        \n","    elif folder == 'Invoice_2':\n","        list2 = Invoice_2\n","        \n","    elif folder == 'Invoice_3':\n","        list2 = Invoice_3\n","        \n","    elif folder == 'Invoice_4':\n","        list2 = Invoice_4\n","        \n","    st2 = list2\n","    \n","    list1 = re.split(r'\\s+|[\\n,:/!=\\'€\"_()\\[\\];\\.-]\\s*', st1)\n","    list2 = re.split(r'\\s+|[\\n,:/!=\\'€\"_()\\[\\];\\.-]\\s*', st2)\n","    \n","\n","    list1 = [i for i in list1 if i]\n","    list2 = [i for i in list2 if i]\n","    \n","    st1 =  ' '.join(np.sort(list1))\n","    st2 =  ' '.join(np.sort(list2))\n","    \n","    CER = fastwer.score_sent(st1, st2, char_level=True)\n","    \n","    return CER"]},{"cell_type":"code","execution_count":null,"id":"15878d3d","metadata":{"id":"15878d3d"},"outputs":[],"source":["df_comparison['cos_ggl'] = df_comparison.apply(lambda x: cos_sim((' '.join(x['words'])),str(x['Doc_no'])), axis =1)\n","df_comparison['euc_ggl'] = df_comparison.apply(lambda x: euc_dist(' '.join((x['words'])),str(x['Doc_no'])), axis =1)\n","df_comparison['Jac_ggl'] = df_comparison.apply(lambda x: jaccard((' '.join(x['words'])),str(x['Doc_no'])), axis =1)"]},{"cell_type":"markdown","id":"1bb88729","metadata":{"id":"1bb88729"},"source":["# Notes\n","\n","1. Amazon's Dataframe has doc no as D21 and our google's dataframe has 21\n","2. Amazon's DF Doesn't have jpg in image name; GGl's DF has\n","2. Amazon's Dataframe has some additional column\n","\n","## Next code might need modification based on Amazon's OCR's Dataframe"]},{"cell_type":"markdown","id":"83d6850d","metadata":{"id":"83d6850d"},"source":["# Phase 2 : Calculating metrics"]},{"cell_type":"code","execution_count":null,"id":"ffd4ed08","metadata":{"id":"ffd4ed08"},"outputs":[],"source":["df = pd.read_csv('Phase 2/df_Textract_All dataset_24_6.csv')"]},{"cell_type":"code","execution_count":null,"id":"6e3cc49d","metadata":{"id":"6e3cc49d","outputId":"9df03d2c-a6fa-4db7-d39d-e99e4de6e9de"},"outputs":[{"data":{"text/plain":["Index(['Img_name', 'Response_json', 'Json_path', 'Img_path', 'N_bbox',\n","       'Extracted_text', 'Mean_conf_score', 'Med_conf_score', 'conf_array',\n","       'Ground_truth', 'Dataset_name', 'API', 'Base_path', 'Img_no'],\n","      dtype='object')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"id":"fab75a70","metadata":{"collapsed":true,"id":"fab75a70","outputId":"1a11b443-6744-4aee-bfc2-bac1457d2f48"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Img_name</th>\n","      <th>Dataset_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Fontfrm_Noisec_RE_gs</td>\n","      <td>Noisy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FontLtm_Noisec_RE_gs</td>\n","      <td>Noisy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FontLse_Noisew_RE_gs</td>\n","      <td>Noisy</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Fontnse_Noisep_RE_gs</td>\n","      <td>Noisy</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Fontnsm_Noisep_RE_gs</td>\n","      <td>Noisy</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>M_Img_WP_D24_L2_r35_a0_b0</td>\n","      <td>SmartDocQA</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>M_Img_WP_D24_L3_r35_a-5_b10</td>\n","      <td>SmartDocQA</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>M_Img_WP_D24_L4_r35_a0_b0</td>\n","      <td>SmartDocQA</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>M_Img_WP_D24_L3_r35_a0_b0</td>\n","      <td>SmartDocQA</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>M_Img_WP_D24_L2_r35_a-5_b10</td>\n","      <td>SmartDocQA</td>\n","    </tr>\n","    <tr>\n","      <th>4434</th>\n","      <td>X51005757324</td>\n","      <td>SROIE</td>\n","    </tr>\n","    <tr>\n","      <th>4435</th>\n","      <td>X51005711401</td>\n","      <td>SROIE</td>\n","    </tr>\n","    <tr>\n","      <th>4436</th>\n","      <td>X51006414675</td>\n","      <td>SROIE</td>\n","    </tr>\n","    <tr>\n","      <th>4437</th>\n","      <td>X51007846393</td>\n","      <td>SROIE</td>\n","    </tr>\n","    <tr>\n","      <th>4438</th>\n","      <td>X51005568880</td>\n","      <td>SROIE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         Img_name Dataset_name\n","0            Fontfrm_Noisec_RE_gs        Noisy\n","1            FontLtm_Noisec_RE_gs        Noisy\n","2            FontLse_Noisew_RE_gs        Noisy\n","3            Fontnse_Noisep_RE_gs        Noisy\n","4            Fontnsm_Noisep_RE_gs        Noisy\n","144     M_Img_WP_D24_L2_r35_a0_b0   SmartDocQA\n","145   M_Img_WP_D24_L3_r35_a-5_b10   SmartDocQA\n","146     M_Img_WP_D24_L4_r35_a0_b0   SmartDocQA\n","147     M_Img_WP_D24_L3_r35_a0_b0   SmartDocQA\n","148   M_Img_WP_D24_L2_r35_a-5_b10   SmartDocQA\n","4434                 X51005757324        SROIE\n","4435                 X51005711401        SROIE\n","4436                 X51006414675        SROIE\n","4437                 X51007846393        SROIE\n","4438                 X51005568880        SROIE"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["df[['Img_name','Dataset_name']].groupby(by = df['Dataset_name']).head(5)"]},{"cell_type":"code","execution_count":null,"id":"9d3924e3","metadata":{"id":"9d3924e3"},"outputs":[],"source":["df['Ground_truth'] = df['Ground_truth'].to_string()\n","df['Extracted_text'] = df['Extracted_text'].to_string()"]},{"cell_type":"code","execution_count":null,"id":"97b6a814","metadata":{"id":"97b6a814"},"outputs":[],"source":["def cleaning_text(text):\n","    list1 = re.split(r'\\s+|[,:/!=\\'€\"_()\\[\\];\\.-]\\s*', text)\n","    list1 = [i for i in list1 if i]\n","    text = ' '.join(list1)\n","    text = text.lower()\n","    return text\n","\n","df['Extracted_text_cleaned'] = df['Extracted_text'].apply(lambda x:cleaning_text(x))\n","df['Ground_truth_cleaned'] = df['Ground_truth'].apply(lambda x:cleaning_text(x))"]},{"cell_type":"code","execution_count":null,"id":"72504d09","metadata":{},"outputs":[],"source":["def CER(original, extracted):\n","    CER = fastwer.score_sent(extracted, original, char_level=True)\n","    return CER\n","\n","df['CER'] = df.apply(lambda x : CER(x['Ground_truth_cleaned'], x['Extracted_text_cleaned']), axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"cdf74c46","metadata":{"id":"cdf74c46"},"outputs":[],"source":["def WER(original, extracted):\n","    WER = fastwer.score_sent(extracted, original)\n","    return WER\n","\n","df['WER'] = df.apply(lambda x : WER(x['Ground_truth_cleaned'], x['Extracted_text_cleaned']), axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"955e5d53","metadata":{"id":"955e5d53"},"outputs":[],"source":["def Jaccard(original, extracted):\n","    list1 = original.split()\n","    list2 = extracted.split()\n","    \n","    intersection = len(list(set(list1).intersection(set(list2))))\n","    union = (len(list1) + len(list2)) - intersection\n","    return float(intersection / union)\n","\n","df['Jaccard Index'] = df.apply(lambda x : Jaccard(x['Ground_truth_cleaned'], x['Extracted_text_cleaned']), axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"a41b6662","metadata":{"id":"a41b6662"},"outputs":[],"source":["count_vectorizer = CountVectorizer(stop_words='english')\n","count_vectorizer = CountVectorizer()\n","\n","def cos(original, extracted):\n","    \n","    document = [original, extracted]\n","    document = count_vectorizer.fit_transform(document)\n","    cos_simm = cosine_similarity(document, document)\n","\n","    \n","    return (cos_simm[1][0])\n","\n","df['Cosine Metrics'] = df.apply(lambda x : cos(x['Ground_truth_cleaned'], x['Extracted_text_cleaned']), axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"0dd7e003","metadata":{"id":"0dd7e003"},"outputs":[],"source":["def word_ratio(original, extracted):\n","    l1 = len(original.split())\n","    l2 = len(extracted.split())\n","    return (l2/l1)\n","\n","df['N_word_ratio'] = df.apply(lambda x : word_ratio(x['Ground_truth_cleaned'], x['Extracted_text_cleaned']), axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"235951f4","metadata":{"id":"235951f4"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"b349621b","metadata":{"id":"b349621b"},"source":["# Doubts\n","1. N_word_ratio is greater than 1 also.\n","2. how to split on \\ in regex, use of \\s* at last in regex"]}],"metadata":{"colab":{"name":"Cleaned pipeline.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":5}
