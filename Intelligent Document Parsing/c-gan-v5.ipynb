{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install git+https://www.github.com/keras-team/keras-contrib.git","metadata":{"execution":{"iopub.status.busy":"2023-03-21T14:28:12.789118Z","iopub.execute_input":"2023-03-21T14:28:12.789622Z","iopub.status.idle":"2023-03-21T14:28:28.916919Z","shell.execute_reply.started":"2023-03-21T14:28:12.789528Z","shell.execute_reply":"2023-03-21T14:28:28.914694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example of preparing the horses and zebra dataset\nfrom os import listdir\nfrom numpy import asarray\nfrom numpy import vstack\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nfrom random import random\nfrom numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy import asarray\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model, load_model\nfrom keras.models import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Activation\nfrom keras.layers import Concatenate\nfrom keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\nfrom matplotlib import pyplot","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-21T14:28:28.919109Z","iopub.execute_input":"2023-03-21T14:28:28.920487Z","iopub.status.idle":"2023-03-21T14:28:34.857350Z","shell.execute_reply.started":"2023-03-21T14:28:28.920448Z","shell.execute_reply":"2023-03-21T14:28:34.856324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install scikit-image","metadata":{"execution":{"iopub.status.busy":"2023-03-21T14:28:34.858914Z","iopub.execute_input":"2023-03-21T14:28:34.859552Z","iopub.status.idle":"2023-03-21T14:28:44.250648Z","shell.execute_reply.started":"2023-03-21T14:28:34.859515Z","shell.execute_reply":"2023-03-21T14:28:44.249247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example of calculating the frechet inception distance in Keras\nimport numpy\nfrom numpy import cov\nfrom numpy import trace\nfrom numpy import iscomplexobj\nfrom numpy import asarray\nfrom numpy.random import randint\nfrom scipy.linalg import sqrtm\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.datasets.mnist import load_data\nfrom skimage.transform import resize\n \n# scale an array of images to a new size\ndef scale_images(images, new_shape):\n    images_list = list()\n    for image in images:\n    # resize with nearest neighbor interpolation\n        new_image = resize(image, new_shape, 0)\n        # store\n        images_list.append(new_image)\n    return asarray(images_list)\n \n# calculate frechet inception distance\ndef calculate_fid(model, images1, images2):\n # calculate activations\n    act1 = model.predict(images1)\n    act2 = model.predict(images2)\n    print('Inceptionv3 prediction done')\n    # calculate mean and covariance statistics\n    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n    # calculate sum squared difference between means\n    ssdiff = numpy.sum((mu1 - mu2)**2.0)\n    # calculate sqrt of product between cov\n    covmean = sqrtm(sigma1.dot(sigma2))\n    # check and correct imaginary numbers from sqrt\n    if iscomplexobj(covmean):\n        covmean = covmean.real\n    # calculate score\n    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n    return fid\n \n# prepare the inception v3 model\nmodel = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n# # define two fake collections of images\n# images1 = randint(0, 255, 10*32*32*3)\n# images1 = images1.reshape((10,32,32,3))\n# images2 = randint(0, 255, 10*32*32*3)\n# images2 = images2.reshape((10,32,32,3))\n# print('Prepared', images1.shape, images2.shape)\n# # convert integer to floating point values\n# images1 = images1.astype('float32')\n# images2 = images2.astype('float32')\ndef FID(images1,images2):    \n    # resize images\n    images1 = scale_images(images1, (299,299,3))\n    images2 = scale_images(images2, (299,299,3))\n    print('Scaled', images1.shape, images2.shape)\n    # pre-process images\n    images1 = preprocess_input(images1)\n    images2 = preprocess_input(images2)\n    print('Preprocessed_Images')\n#    print('Calculating FID')\n    fid = calculate_fid(model, images1, images2)\n    print('FID (different): %.3f' % fid)\n    return fid","metadata":{"execution":{"iopub.status.busy":"2023-03-21T14:28:44.253847Z","iopub.execute_input":"2023-03-21T14:28:44.254291Z","iopub.status.idle":"2023-03-21T14:28:50.997051Z","shell.execute_reply.started":"2023-03-21T14:28:44.254259Z","shell.execute_reply":"2023-03-21T14:28:50.996060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\n\n# define the discriminator model\ndef define_discriminator(image_shape):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02, seed = 20)\n\t# source image input convoluted sie = (w-f+2p)/s + 1\n\tin_image = Input(shape=image_shape)\n\t# C64 - (256-4+2*2)/2 + 1 = 128+1\n\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C128 \n\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = InstanceNormalization(axis=-1)(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C256\n\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = InstanceNormalization(axis=-1)(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C512\n\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = InstanceNormalization(axis=-1)(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# second last output layer\n\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n\td = InstanceNormalization(axis=-1)(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# patch output\n\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n\t# define model\n\tmodel = Model(in_image, patch_out)\n\t# compile model\n\tmodel.compile(loss='mse', optimizer=Adam(lr=0.000005, beta_1=0.5), loss_weights=[0.5])\n\treturn model\n \n# generator a resnet block\ndef resnet_block(n_filters, input_layer):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02, seed = 20)\n\t# first layer convolutional layer\n\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n\tg = InstanceNormalization(axis=-1)(g)\n\tg = Activation('relu')(g)\n\t# second convolutional layer\n\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n\tg = InstanceNormalization(axis=-1)(g)\n\t# concatenate merge channel-wise with input layer\n\tg = Concatenate()([g, input_layer])\n\treturn g\n \n# define the standalone generator model\ndef define_generator(image_shape, n_resnet=7):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02, seed = 20)\n\t# image input\n\tin_image = Input(shape=image_shape)\n\t# c7s1-64\n\tg = Conv2D(32, (9,9), padding='same', kernel_initializer=init)(in_image)\n\tg = InstanceNormalization(axis=-1)(g)\n\tg = Activation('relu')(g)\n\t# d128\n\tg = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n\tg = InstanceNormalization(axis=-1)(g)\n\tg = Activation('relu')(g)\n\t# d256\n\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n\tg = InstanceNormalization(axis=-1)(g)\n\tg = Activation('relu')(g)\n\t# R256\n\tfor _ in range(n_resnet):\n\t\tg = resnet_block(128, g)\n\t# u128\n\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n\tg = InstanceNormalization(axis=-1)(g)\n\tg = Activation('relu')(g)\n\t# u64\n\tg = Conv2DTranspose(32, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n\tg = InstanceNormalization(axis=-1)(g)\n\tg = Activation('relu')(g)\n\t# c7s1-3\n\tg = Conv2D(3, (9,9), padding='same', kernel_initializer=init)(g)\n\tg = InstanceNormalization(axis=-1)(g)\n\tout_image = Activation('tanh')(g)\n\t# define model\n\tmodel = Model(in_image, out_image)\n\treturn model\n \n# define a composite model for updating generators by adversarial and cycle loss\ndef define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n\t# ensure the model we're updating is trainable\n\tg_model_1.trainable = True\n\t# mark discriminator as not trainable\n\td_model.trainable = False\n\t# mark other generator model as not trainable\n\tg_model_2.trainable = False\n\t# discriminator element\n\tinput_gen = Input(shape=image_shape)\n\tgen1_out = g_model_1(input_gen)\n\t# forward cycle\n\toutput_f = g_model_2(gen1_out)\n\toutput_d = d_model(gen1_out)\n\t# identity element\n\tinput_id = Input(shape=image_shape)\n\t# backward cycle\n\tgen2_out = g_model_2(input_id)\n\toutput_b = g_model_1(gen2_out)\n\toutput_id = g_model_1(input_id)\n\t# define model graph\n\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n\t# define optimization algorithm configuration\n\topt = Adam(lr=0.000005, beta_1=0.5)\n\t# compile model with weighting of least squares loss and L1 loss\n\tmodel.compile(loss=['mse', 'mse', 'mse', 'mse'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n\treturn model\n \n# load and prepare training images\ndef load_real_samples(filename):\n\t# load the dataset\n\tdata = load(filename)\n\t# unpack arrays\n\tX1, X2 = data['arr_0'], data['arr_1']\n\t# scale from [0,255] to [-1,1]\n\tX1 = (X1 - 127.5) / 127.5\n\tX2 = (X2 - 127.5) / 127.5\n\treturn [X1, X2]\n \n\n# select a batch of random samples, returns images and target\ndef generate_real_samples(dataset, n_samples, patch_shape, i, bat_per_epo):\n#\tchoose random instances\n\ti = i - bat_per_epo*math.floor(float(i/bat_per_epo))\n#\tix = randint(0, dataset.shape[0], n_samples)\n\t# retrieve selected images\n\tix = range(n_samples*i,n_samples*(i+1))\n\tX = dataset[ix]\n\t# generate 'real' class labels (1)\n\ty = ones((n_samples, patch_shape, patch_shape, 1))\n\treturn X, y\n \n# generate a batch of images, returns images and targets\ndef generate_fake_samples(g_model, dataset, patch_shape):\n\t# generate fake instance\n\tX = g_model.predict(dataset)\n\t# create 'fake' class labels (0)\n\ty = zeros((len(X), patch_shape, patch_shape, 1))\n\treturn X, y\n \n# save the generator models to file\n#def save_models(step, g_model_AtoB, g_model_BtoA):\ndef save_models(step, g_model_BtoA):\n\t# save the first generator model\n#\tfilename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n#\tg_model_AtoB.save(filename1)\n\t# save the second generator model\n\tfilename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n\tg_model_BtoA.save(filename2)\n\tprint('>Saved: %s ' % (filename2))\n\n \n# generate samples and save as a plot and save the model\ndef summarize_performance(step, data, OG, g_model, trainX, name, fid_min, n_samples=17):\n\t# select a sample of input images\n\t# unpack arrays\n\tX1 = data['arr_0']\n\tX2 = OG['arr_0']\n\t# scale from [0,255] to [-1,1]\n\tX1 = (X1 - 127.5) / 127.5\n\tX2 = (X2 - 127.5) / 127.5\n\tX_in = X1\n\t#X_in, _ = generate_real_samples(trainX, n_samples, 0)\n\t# generate translated images\n\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n\t# scale all pixels from [-1,1] to [0,1]\n\tX_in = (X_in + 1) / 2.0\n\tX2 = (X2 + 1) / 2.0\n\tX_out = (X_out + 1) / 2.0\n\tprint(X2.shape, X_out.shape)\n\tfid = FID(X2,X_out)\n# \tif fid < fid_min:\n# \t# plot real images\n# \t\tfor j in range(7):\n# \t\t\tfor i in range(5):\n# \t\t\t\tpyplot.subplot(2, 5, 1 + i)\n# \t\t\t\tpyplot.axis('off')\n# \t\t\t\tpyplot.imshow(X_in[5*j + i])\n# \t# plot translated image\n# \t\t\tfor i in range(5):\n# \t\t\t\tpyplot.subplot(2, 5, 1 + 5 + i)\n# \t\t\t\tpyplot.axis('off')\n# \t\t\t\tpyplot.imshow(X_out[5*j + i])\n# \t# save plot to file\n# \t\t\tfilename1 = '%s_generated_plot_%06d_iter_%d.png' % (name, (step+1),j)\n# \t\t\tpyplot.savefig(filename1)\n# \t\t\tpyplot.close()          \n\treturn fid\n \n# update image pool for fake images\ndef update_image_pool(pool, images, max_size=50):\n\tselected = list()\n\tfor image in images:\n\t\tif len(pool) < max_size:\n\t\t\t# stock the pool\n\t\t\tpool.append(image)\n\t\t\tselected.append(image)\n\t\telif random() < 0.5:\n\t\t\t# use image, but don't add it to the pool\n\t\t\tselected.append(image)\n\t\telse:\n\t\t\t# replace an existing image and use replaced image\n\t\t\tix = randint(0, len(pool))\n\t\t\tselected.append(pool[ix])\n\t\t\tpool[ix] = image\n\treturn asarray(selected)\n \n# train cyclegan models\ndef train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n\t# define properties of the training run\n\tdif_df = pd.DataFrame(columns = ['Iteration', 'FID'])\n\tn_epochs, n_batch, = 500, 7\n\t# determine the output square shape of the discriminator\n\tn_patch = d_model_A.output_shape[1]\n\t# unpack dataset\n\ttrainA, trainB = dataset\n\t#trainB = np.concatenate((trainB,trainB), axis = 0)\n\t#trainA = np.random.rand(*trainA.shape).argsort(axis=0)\n\tprint(trainA.shape, trainB.shape)\n\t# prepare image pool for fakes\n\tpoolA, poolB = list(), list()\n\t# calculate the number of batches per training epoch 119, 526\n\tbat_per_epo = int(len(trainA) / n_batch) #434/6 = 72\n\t# calculate the number of training iterations\n\tn_steps = int(bat_per_epo * n_epochs) #200000\n\tdf = pd.DataFrame(columns = ['i','g_loss2','g_loss1','dA_loss1','dA_loss2','dB_loss1','dB_loss2','_1','_2','_3','_4','_5','_6','_7','_8'])\n\tdata = load('/kaggle/input/mb-test/MB_Testing_all.npz')\n\tOG = load('/kaggle/input/mb-testing-og/Mb_blur_Testing_OG.npz')\n\tfid_min = 20\n\tprint(f'Batch per epoch is {bat_per_epo} \\nN_steps is {n_steps}')\n\t# manually enumerate epochs\n\tlrt = 0.002\n\tfor i in range(n_steps):\n\t\t# select a batch of real samples\n\t\tX_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch, i, bat_per_epo)\n\t\tX_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch, i, bat_per_epo)\n\t\t# generate a batch of fake samples\n\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n\t\t# update fakes from pool\n\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n\t\t# update generator B->A via adversarial and cycle loss\n\t\tg_loss2, _1, _2, _3, _4  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n# \t\tprint(g_loss2,_1,_2,_3,_4)\n# \t\tprint(c_model_BtoA.metrics_names)['loss', 'model_2_loss', 'model_1_loss', 'model_loss', 'model_1_1_loss']\n# \t\tprint(d_model_B.metrics_names) ['loss']\n# \t\tprint(g_model_AtoB.metrics_names) []\n\t\t# update discriminator for A -> [real/fake]\n\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n\t\t# update generator A->B via adversarial and cycle loss\n\t\tg_loss1, _5, _6, _7, _8 = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n\t\t# update discriminator for B -> [real/fake]\n\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n\t\tdf.loc[len(df.index)] = [i,g_loss2,g_loss1,dA_loss1,dA_loss2,dB_loss1,dB_loss2,_1,_2,_3,_4,_5,_6,_7,_8]\n\t\t# summarize performance\n\t\tprint('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n\t\t# evaluate the model performance every so often\n\t\tif 4*((i)) % (bat_per_epo) == 0:\n\t\t\tfid_o = summarize_performance(i, data, OG, g_model_BtoA, trainB, 'BtoA', fid_min)\n\t\t\tprint(fid_o, fid_min)\n\t\t\tdf.to_csv('Losses.csv')\n\t\t\t#summarize_performance(i,data, OG, g_model_BtoA, trainB, 'BtoA')\n\t\t\tdif_df.loc[len(dif_df)] = [i,fid_o]\n\t\t\tif fid_o < fid_min:\n\t\t\t\tfid_min = fid_o\n\t\t\t\tsave_models(i,g_model_BtoA)\n\t\t\t\tfilename2 = 'g_model_BtoA_%06d.h5' % (i+1)\n\t\t\t\tg_model_AtoB.save('g_model_AtoB.h5')     \n\t\t\t\td_model_A.save('d_model_A.h5')\n\t\t\t\td_model_B.save('d_model_B.h5')\n\t\t\t\tc_model_AtoB.save('c_model_AtoB.h5')\n\t\t\t\tc_model_BtoA.save('c_model_BtoA.h5')\n\t\t\ta = 'DIF' + str(i) + '.csv'\n\t\t\tdif_df.to_csv('DIF.csv')\n\ndataset = load_real_samples('/kaggle/input/mb-training-full-data1/MB_Blur_patches_all_files_May1.npz')\nprint('Loaded', dataset[0].shape, dataset[1].shape)\n# define input shape based on the loaded dataset\nimage_shape = dataset[0].shape[1:]\n# generator: A -> B\ng_model_AtoB = define_generator(image_shape)\n# generator: B -> A\ng_model_BtoA = define_generator(image_shape)\n# discriminator: A -> [real/fake]\nd_model_A = define_discriminator(image_shape, lrt)\n# discriminator: B -> [real/fake]\nd_model_B = define_discriminator(image_shape, lrt)\n# composite: A -> B -> [real/fake, A]\nc_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape, lrt)\n# composite: B -> A -> [real/fake, B]\nc_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape, lrt)\n# g_model_AtoB = load_model('/kaggle/input/most-recent-models-21-march/g_model_AtoB.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n# g_model_BtoA = load_model('/kaggle/input/most-recent-models-21-march/c_model_BtoA.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n# d_model_A = load_model('/kaggle/input/most-recent-models-21-march/d_model_A.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n# d_model_B = load_model('/kaggle/input/most-recent-models-21-march/d_model_B.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n# c_model_AtoB = load_model('/kaggle/input/c-atob-march21/c_model_AtoB.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n# c_model_BtoA = load_model('/kaggle/input/most-recent-models-21-march/c_model_BtoA.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n# train models\ntrain(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T14:28:51.002386Z","iopub.execute_input":"2023-03-21T14:28:51.004699Z","iopub.status.idle":"2023-03-21T14:29:06.541294Z","shell.execute_reply.started":"2023-03-21T14:28:51.004651Z","shell.execute_reply":"2023-03-21T14:29:06.539267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}